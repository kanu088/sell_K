{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ac7eeacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\dell\\anaconda3\\lib\\site-packages (4.18.1)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (4.10.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dell\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ae086598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b5acb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66db4b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39b61275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product that we want to search : guitar\n"
     ]
    }
   ],
   "source": [
    "val = input('Enter the product that we want to search : ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea8210b",
   "metadata": {},
   "source": [
    "Q2. In the above question, now scrape the following details of each product listed in first 3 pages of your search\n",
    "results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then\n",
    "scrape all the products available under that product name. Details to be scraped are: \"Brand\n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and\n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e1e2952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d9befcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b43dfbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar=driver.find_element(By.XPATH,\"//input[@type='text']\")\n",
    "search_bar.send_keys(\"guitar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c36b7a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "button=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d3a076f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping URLs to open the pages\n",
    "urls = []          # empty list\n",
    "for i in range(0,1):     \n",
    "    page_url = driver.find_elements(By.XPATH,\"//a[@class='a-link-normal a-text-normal']\")\n",
    "    for i in page_url:\n",
    "        urls.append(i.get_attribute(\"href\"))\n",
    "        next_btn = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[1]/div[1]/div/span[1]/div[1]/div[62]/div/div/span/a[4]\")\n",
    "        next_btn.click()\n",
    "        time.sleep(3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1b372b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c1483e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making empty list and scraping required data\n",
    "brand_name = []\n",
    "product_name = []\n",
    "prices = []\n",
    "exchange = []\n",
    "exp_delivery = []\n",
    "availability = []\n",
    "other_details = []\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "     \n",
    "    #scraping brand name \n",
    "    try:\n",
    "        brand = driver.find_element(By_XPATH,\"//a[@id='bylineInfo']\")\n",
    "        brand_name.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        brand_name.append('-')\n",
    "    \n",
    "    \n",
    "    # scraping Name of the Product\n",
    "    try:\n",
    "        product = driver.find_element(By.XPATH,\"//span[@id='productTitle']\")\n",
    "        product_name.append(product.text)\n",
    "    except NoSuchElementException:\n",
    "        product_name.append('-')\n",
    "        \n",
    "        \n",
    "         #scraping price of the product\n",
    "    try:\n",
    "        price = driver.find_element(By.XPATH,\"//td[@class='a-span12']\")\n",
    "        prices.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        prices.append('-')\n",
    "        \n",
    "        \n",
    "    #scraping return/exchange\n",
    "    try:\n",
    "        exch = driver.find_element(By.XPATH,\"//span[@class='a-declarative']/div/a\")\n",
    "        exchange.append(exch.text)\n",
    "    except NoSuchElementException:\n",
    "        exchange.append('-')\n",
    "        \n",
    "\n",
    "    #scraoing expected delivery\n",
    "    try:\n",
    "        delivery = driver.find_element(By.XPATH,\"//div[@class='a-section a-spacing-mini']/b\")\n",
    "        exp_delivery.append(delivery.text)\n",
    "    except NoSuchElementException:\n",
    "        exp_delivery.append('-')\n",
    "        \n",
    "\n",
    "    #scraping availability information\n",
    "    try:\n",
    "        avail = driver.find_element(By.XPATH,\"//span[@class='a-size-medium a-color-success']\")\n",
    "        availability.append(avail.text)\n",
    "    except NoSuchElementException:\n",
    "        availability.append('-')\n",
    "        \n",
    "        \n",
    "        #other details\n",
    "    try:\n",
    "        oth_det = driver.find_element(By.XPATH,\"//ul[@class='a-unordered-list a-vertical a-spacing-mini']\")\n",
    "        other_details.append(oth_det.text)\n",
    "    except NoSuchElementException:\n",
    "        other_details.append('-')\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f69cce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(brand_name),\n",
    "len(product_name),\n",
    "len(prices),\n",
    "len(exchange),\n",
    "len(exp_delivery),\n",
    "len(availability),\n",
    "len(other_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "284137c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Name of the Product</th>\n",
       "      <th>Price</th>\n",
       "      <th>Return/Exchange</th>\n",
       "      <th>Expected Delivery</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Other Details</th>\n",
       "      <th>Product URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Brand Name, Name of the Product, Price, Return/Exchange, Expected Delivery, Availability, Other Details, Product URL]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guitar = pd.DataFrame({})\n",
    "guitar['Brand Name'] = brand_name\n",
    "guitar['Name of the Product'] = product_name\n",
    "guitar['Price'] = prices\n",
    "guitar['Return/Exchange'] = exchange\n",
    "guitar['Expected Delivery'] = exp_delivery\n",
    "guitar['Availability'] = availability\n",
    "guitar['Other Details'] = other_details\n",
    "guitar['Product URL'] = urls\n",
    "guitar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c485c4",
   "metadata": {},
   "source": [
    "Q3 : Write a python program to access the search bar and search button on images.google.com and scrape 10 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’guitar and cakes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "540a191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5afb3905",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://images.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1ea97d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar=driver.find_element(By.XPATH,'//textarea[@class=\"gLFyf\"]')\n",
    "search_bar.send_keys(\"cakes images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8686eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "button=driver.find_element(By.XPATH,\"//button[@class='Tg7LZd']\")\n",
    "button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7374d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(20):\n",
    "    driver.execute_script(\"window.scrollBy(0,500)\")\n",
    "        \n",
    "imgs = driver.find_elements(By.XPATH,\"//img[@class='rg_i Q4LuWd']\")\n",
    "img_url = []\n",
    "for image in imgs:\n",
    "    source = image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] == 'http'):\n",
    "            img_url.append(source)\n",
    "        \n",
    "\n",
    "for i in range(len(urls)):\n",
    "    if i >= 10:\n",
    "        breakBy.XPATH,\n",
    "    print(\"Downloading {0} of {1} images\" .format(i,10))\n",
    "    response = requests.get(urls[i])\n",
    "    file = open(r\"c:\\Users\\dell\\Dekshtop\\parth pic_files\"+str(i)+\".jpg\",\"wb\")\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7024291",
   "metadata": {},
   "source": [
    "4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com\n",
    "and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand\n",
    "Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”,\n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the\n",
    "details is missing then replace it by “- “. Save your results in a dataframe and CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "80566f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "08ab870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3bf36f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar=driver.find_element(By.XPATH,\"//input[@type='text']\")\n",
    "search_bar.send_keys(\"pixel 4A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5739f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "button=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/button\")\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bb4d087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "page1_url = []\n",
    "urls = driver.find_elements(By.XPATH,\"//a[@class='_1fQZEK']\")\n",
    "for url in urls:\n",
    "    page1_url.append(url.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "517daf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bbfd401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list\n",
    "Smartphones = ({})\n",
    "Smartphones['Brand'] = []\n",
    "Smartphones['Phone name'] = []\n",
    "Smartphones['Colour'] = []\n",
    "Smartphones['RAM'] = []\n",
    "Smartphones['Storage(ROM)'] = []\n",
    "Smartphones['Primary Camera'] = []\n",
    "Smartphones['Secondary Camera'] = []\n",
    "Smartphones['Display Size'] = []\n",
    "Smartphones['Battery Capacity'] = []\n",
    "Smartphones['Price'] = []\n",
    "Smartphones['URL'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "35337ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data from each url of page 1\n",
    "for url in page1_url:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    \n",
    "    #scraping brand name of smartphone\n",
    "    try:\n",
    "        brand_tags = driver.find_element(By.XPATH,\"//span[@class='B_NuCI']\")\n",
    "        Smartphones['Brand'].append(brand_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Brand'].append('-')\n",
    "    \n",
    "    \n",
    "    # scraping name of smartphones\n",
    "    try:\n",
    "        name_tags = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][1]/table/tbody/tr[3]/td[2]/ul/li\")\n",
    "        Smartphones['Phone name'].append(name_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Phone name'].append('-')\n",
    "        \n",
    "        \n",
    "        #scraping colour of smartphone\n",
    "    try:\n",
    "        color_tags = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][1]/table/tbody/tr[4]/td[2]/ul/li\")\n",
    "        Smartphones['Colour'].append(color_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Colour'].append('-')\n",
    "        \n",
    "    # scraping RAM data of smartphone\n",
    "    try:\n",
    "        ram_tags = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][4]/table[1]/tbody/tr[2]/td[2]/ul/li\")\n",
    "        Smartphones['RAM'].append(ram_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['RAM'].append('-')\n",
    "        \n",
    "    #scraping ROM data of smartphones\n",
    "    try:\n",
    "        rom = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][4]/table[1]/tbody/tr[1]/td[2]/ul/li\")\n",
    "        Smartphones['Storage(ROM)'].append(rom.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Storage(ROM)'].append('-')\n",
    "        \n",
    "    # scraping  Primary camera data of smartphone\n",
    "    try:\n",
    "        pri =driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][5]/table[1]/tbody/tr[2]/td[2]/ul/li\")\n",
    "        Smartphones['Primary Camera'].append(pri.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Primary Camera'].append('-')\n",
    "        \n",
    "        \n",
    "        #scraping display size data of smartphone\n",
    "    try:\n",
    "        disp = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][2]/div\")\n",
    "        if disp.text != 'Display Features' : raise NoSuchElementException\n",
    "        disp_size = driver.find_element_by_xpath(\"//div[@class='_3k-BhJ'][2]/table[1]/tbody/tr[1]/td[2]/ul/li\")\n",
    "        Smartphones['Display Size'].append(disp_size.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Display Size'].append('-')\n",
    "        \n",
    "            \n",
    "    # scraping the battery capacity of smartphone\n",
    "    try:\n",
    "        if driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][10]/div\").text != \"Battery & Power Features\" :\n",
    "            if driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][9]/div\").text == \"Battery & Power Features\" :\n",
    "                bat_tags = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][9]/table/tbody/tr/td[1]\")\n",
    "                if bat_tags.text != \"Battery Capacity\" : raise NoSuchElementException\n",
    "                bat_capa = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][9]/table/tbody/tr/td[2]/ul/li\")\n",
    "            elif driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][8]/div\").text == \"Battery & Power Features\" :\n",
    "                bat_tags = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][8]/table/tbody/tr/td[1]\")\n",
    "                if bat_tags.text != \"Battery Capacity\" : raise NoSuchElementException\n",
    "                bat_capa = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][8]/table/tbody/tr/td[2]/ul/li\")\n",
    "            else:\n",
    "                raise NoSuchElementException\n",
    "        else :\n",
    "            bat_tags = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][10]/table/tbody/tr/td[1]\")\n",
    "            if bat_tags.text != \"Battery Capacity\" : raise NoSuchElementException\n",
    "            bat_capa = driver.find_element(By.XPATH,\"//div[@class='_3k-BhJ'][10]/table/tbody/tr/td[2]/ul/li\")\n",
    "        Smartphones['Battery Capacity'].append(bat_capa.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Battery Capacity'].append('-')\n",
    "   # scraping price of smartphone\n",
    "    try:\n",
    "        price_tags = driver.find_element(By.XPATH,\"//div[@class='_30jeq3 _16Jk6d']\")\n",
    "        Smartphones['Price'].append(price_tags.text)\n",
    "    except NoSuchElementException:\n",
    "          Smartphones['Price'].append('-')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6edcc656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 24 24 24 0 24 24 24 0\n"
     ]
    }
   ],
   "source": [
    "print(len(Smartphones['Brand']),len(Smartphones['Phone name']), len(Smartphones['Colour']),len(Smartphones['RAM']),len(Smartphones['Primary Camera']),len(Smartphones['Secondary Camera']), len(Smartphones['Display Size']),len(Smartphones['Battery Capacity']), len(Smartphones['Price']), len(Smartphones['URL'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b7412d4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(Smartphones)\n\u001b[0;32m      2\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:1764\u001b[0m, in \u001b[0;36mDataFrame.from_dict\u001b[1;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1759\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for orient parameter. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morient\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1761\u001b[0m     )\n\u001b[0;32m   1763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(data, index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1766\u001b[0m     realdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame.from_dict(Smartphones)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e85029",
   "metadata": {},
   "source": [
    "5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "166960ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0302b411",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.google.co.in/maps'\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "edd43942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter City name that has to be searched : Jaipur\n"
     ]
    }
   ],
   "source": [
    "City = input('Enter City name that has to be searched : ')\n",
    "search_bar = driver.find_element(By.XPATH,'//input[@class=\"searchboxinput xiQnY\"]')\n",
    "search_bar.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dbd8dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar.send_keys(City)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "79af6390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL Extracted:  https://www.google.co.in/maps/place/Jaipur,+Rajasthan/@26.8848298,75.4615659,10z/data=!4m6!3m5!1s0x396c4adf4c57e281:0xce1c63a0cf22e09!8m2!3d26.9124336!4d75.7872709!16zL20vMDE2NzIy?entry=ttu\n",
      "Latitude = 26.8848298, Longitude = 75.4615659\n"
     ]
    }
   ],
   "source": [
    "search_btn = driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div[8]/div[3]/div[1]/div[1]/div/div[2]/div[1]/button/span\")\n",
    "search_btn.click()\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "try:\n",
    "    url_str = driver.current_url\n",
    "    print(\"URL Extracted: \", url_str)\n",
    "    latitude_longitude = re.findall(r'@(.*)data',url_str)\n",
    "    if len(latitude_longitude):\n",
    "        lat_lng_list = latitude_longitude[0].split(\",\")\n",
    "        if len(lat_lng_list)>=2:\n",
    "            latitude = lat_lng_list[0]\n",
    "            longitude = lat_lng_list[1]\n",
    "        print(\"Latitude = {}, Longitude = {}\".format(latitude, longitude))\n",
    "except Exception as e:\n",
    "        print(\"Error: \", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0d8926",
   "metadata": {},
   "source": [
    "6. Write a program to scrap all the available details of best gaming laptops from digit.in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9c1585ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0eab2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.digit.in/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96376d31",
   "metadata": {},
   "source": [
    "7. Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped:\n",
    "“Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b1029109",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e6a6daab",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.forbes.com/?sh=41bd46d2254c\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "44a3e45a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//div[@class='header__left']//button\"}\n  (Session info: chrome=122.0.6261.129); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF69D47AD02+56930]\n\t(No symbol) [0x00007FF69D3EF602]\n\t(No symbol) [0x00007FF69D2A42E5]\n\t(No symbol) [0x00007FF69D2E98ED]\n\t(No symbol) [0x00007FF69D2E9A2C]\n\t(No symbol) [0x00007FF69D32A967]\n\t(No symbol) [0x00007FF69D30BCDF]\n\t(No symbol) [0x00007FF69D3281E2]\n\t(No symbol) [0x00007FF69D30BA43]\n\t(No symbol) [0x00007FF69D2DD438]\n\t(No symbol) [0x00007FF69D2DE4D1]\n\tGetHandleVerifier [0x00007FF69D7F6F8D+3711213]\n\tGetHandleVerifier [0x00007FF69D8504CD+4077101]\n\tGetHandleVerifier [0x00007FF69D84865F+4044735]\n\tGetHandleVerifier [0x00007FF69D519736+706710]\n\t(No symbol) [0x00007FF69D3FB8DF]\n\t(No symbol) [0x00007FF69D3F6AC4]\n\t(No symbol) [0x00007FF69D3F6C1C]\n\t(No symbol) [0x00007FF69D3E68D4]\n\tBaseThreadInitThunk [0x00007FFF94267344+20]\n\tRtlUserThreadStart [0x00007FFF95F226B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m opt_btn \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//div[@class=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheader__left\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]//button\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m opt_btn\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m      3\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:741\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    738\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    739\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 741\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mFIND_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//div[@class='header__left']//button\"}\n  (Session info: chrome=122.0.6261.129); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF69D47AD02+56930]\n\t(No symbol) [0x00007FF69D3EF602]\n\t(No symbol) [0x00007FF69D2A42E5]\n\t(No symbol) [0x00007FF69D2E98ED]\n\t(No symbol) [0x00007FF69D2E9A2C]\n\t(No symbol) [0x00007FF69D32A967]\n\t(No symbol) [0x00007FF69D30BCDF]\n\t(No symbol) [0x00007FF69D3281E2]\n\t(No symbol) [0x00007FF69D30BA43]\n\t(No symbol) [0x00007FF69D2DD438]\n\t(No symbol) [0x00007FF69D2DE4D1]\n\tGetHandleVerifier [0x00007FF69D7F6F8D+3711213]\n\tGetHandleVerifier [0x00007FF69D8504CD+4077101]\n\tGetHandleVerifier [0x00007FF69D84865F+4044735]\n\tGetHandleVerifier [0x00007FF69D519736+706710]\n\t(No symbol) [0x00007FF69D3FB8DF]\n\t(No symbol) [0x00007FF69D3F6AC4]\n\t(No symbol) [0x00007FF69D3F6C1C]\n\t(No symbol) [0x00007FF69D3E68D4]\n\tBaseThreadInitThunk [0x00007FFF94267344+20]\n\tRtlUserThreadStart [0x00007FFF95F226B1+33]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "opt_btn = driver.find_element(By.XPATH,\"//div[@class='header__left']//button\")\n",
    "opt_btn.click()\n",
    "time.sleep(3)\n",
    "\n",
    "blns = driver.find_element(By.XPATH,\"/html/body/div[1]/header/nav/div[3]/ul/li[1]\")\n",
    "blns.click()\n",
    "time.sleep(3)\n",
    "\n",
    "bln_list = driver.find_element(By.XPATH,\"/html/body/div[1]/header/nav/div[3]/ul/li[1]/div[2]/ul/li[2]/a\")\n",
    "bln_list.click()\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360b2678",
   "metadata": {},
   "source": [
    "8. Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted\n",
    "from any YouTube Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1be3d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07efa2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.youtube.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fd9f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar = driver.find_element(By.XPATH,\"//div[@class='ytd-searchbox-spt']/input\")\n",
    "search_bar.send_keys(\"GOT\")     \n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "594e6b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button= driver.find_element(By.XPATH,\"/html/body/ytd-app/div[1]/div/ytd-masthead/div[4]/div[2]/ytd-searchbox/button/yt-icon/yt-icon-shape/icon-shape/div\")\n",
    "search_button.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67158ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    driver.execute_script(\"window.scrollBy(0,10000)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01e3e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "comment_time = []\n",
    "Time = []\n",
    "Likes = []\n",
    "No_of_Likes = []\n",
    "\n",
    "\n",
    "# scrape time when comment was posted\n",
    "tm = driver.find_elements(By.XPATH,\"//a[contains(text(),'ago')]\")\n",
    "for i in tm:\n",
    "    Time.append(i.text)\n",
    "    \n",
    "for i in range(0,len(Time),2):\n",
    "    comment_time.append(Time[i])\n",
    "time.sleep(4)\n",
    "\n",
    "\n",
    "# scrape the comment likes\n",
    "like = driver.find_elements(By.XPATH,\"//span[@class='style-scope ytd-comment-action-buttons-renderer']\")\n",
    "for i in like:\n",
    "    Likes.append(i.text)\n",
    "    \n",
    "for i in range(1,len(Likes),2):\n",
    "    No_of_Likes.append(Likes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc5d3655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(comment_time),len(No_of_Likes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "697c8153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment Time</th>\n",
       "      <th>Comment Upvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Comment Time, Comment Upvotes]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Youtube = pd.DataFrame({})\n",
    "Youtube['Comment Time'] = comment_time[:500]\n",
    "Youtube['Comment Upvotes'] = No_of_Likes[:500]\n",
    "Youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d66f623",
   "metadata": {},
   "source": [
    "9. Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in\n",
    "“London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, overall\n",
    "reviews, privates from price, dorms from price, facilities and property description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "abd1653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7c1d8c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.hostelworld.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c6dc648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar = driver.find_element(By.XPATH,\"//input[@type='text']\")\n",
    "search_bar.send_keys('London')     \n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e9bd762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_but = driver.find_element(By.XPATH,'//button[@class=\"btn-content medium-button icon-only\"]')\n",
    "search_but.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "62bc9189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping URLs to open the pages\n",
    "urls = []          # empty list\n",
    "for i in range(0,1):  \n",
    "    page_url = driver.find_elements(By.XPATH,'//a[@class=\"property-card-container horizontal\"]')\n",
    "    for i in page_url:\n",
    "        urls.append(i.get_attribute(\"href\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5a77b743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d4438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making empty list and scraping required data\n",
    "hostel_name = []\n",
    "distance = []\n",
    "private_prices = []\n",
    "doms_price = []\n",
    "rating = []\n",
    "total_review = []\n",
    "overall_review = []\n",
    "facility = []\n",
    "product_des = []\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "     \n",
    "    #scraping hostel name \n",
    "    try:\n",
    "        hostel = driver.find_element(By.XPATH,'//div[@class=\"property-name\"]//span')\n",
    "        hostel_name.append(hostel.text)\n",
    "    except NoSuchElementException:\n",
    "        hostel_name.append('-')\n",
    "        \n",
    "        #scraping distance\n",
    "    try:\n",
    "        dis = driver.find_element(By.XPATH,'//span[@class=\"distance-description\"]')\n",
    "        distance.append(dis.text)\n",
    "    except NoSuchElementException:\n",
    "        distance.append('-')\n",
    "    \n",
    "       #scraping private price\n",
    "    try:\n",
    "        pp = driver.find_element(By.XPATH,'//strong[@class=\"current\"]')\n",
    "        private_prices.append(pp.text)\n",
    "    except NoSuchElementException:\n",
    "        private_prices.append('-')\n",
    "    \n",
    "    #scraping doms price\n",
    "    try:\n",
    "        dp = driver.find_element(By.XPATH,'//strong[class=\"current\"]')\n",
    "        doms_price.append(dp.text)\n",
    "    except NoSuchElementException:\n",
    "        doms_price.append('-')\n",
    "        \n",
    "        #scraping rating\n",
    "    try:\n",
    "        rate = driver.find_element(By.XPATH,'//span[@class=\"number\"]')\n",
    "        rating.append(rate.text)\n",
    "    except NoSuchElementException:\n",
    "        rating.append('-')\n",
    "        \n",
    "         #scraping total review\n",
    "    try:\n",
    "        review = driver.find_element(By.XPATH,'//div[@class=\"reviews\"]')\n",
    "        total_review.append(review.text)\n",
    "    except NoSuchElementException:\n",
    "        total_review.append('-')\n",
    "       #scraping overall review\n",
    "    try:\n",
    "        reviewall = driver.find_element(By.XPATH,'//div[@class=\"content\"]')\n",
    "        overall_review.append(reviewall.text)\n",
    "    except NoSuchElementException:\n",
    "        overall_review.append('-')\n",
    "        \n",
    "          #scraping Facility\n",
    "    try:\n",
    "        fac_hostel = driver.find_element(By.XPATH,'//div[@class=\"content\"]')\n",
    "        facility.append(fac_hostel.text)\n",
    "    except NoSuchElementException:\n",
    "        facility.append('-')\n",
    "        \n",
    "                #scraping product description\n",
    "    try:\n",
    "        pd = driver.find_element(By.XPATH,'//h4[@class=\"title-4\"]')\n",
    "        product_des.append(pd.text)\n",
    "    except NoSuchElementException:\n",
    "        product_des.append('-')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c3bbf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
